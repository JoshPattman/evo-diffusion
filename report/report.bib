@article{original-paper,
  author   = {Watson, Richard A. and Wagner, Günter P. and Pavlicev, Mihaela and Weinreich, Daniel M. and Mills, Rob},
  title    = {THE EVOLUTION OF PHENOTYPIC CORRELATIONS AND “DEVELOPMENTAL MEMORY”},
  journal  = {Evolution},
  volume   = {68},
  number   = {4},
  pages    = {1124-1138},
  keywords = {Adaptation, associative learning, evolvability, evo-devo},
  doi      = {https://doi.org/10.1111/evo.12337},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/evo.12337},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/evo.12337},
  abstract = {Development introduces structured correlations among traits that may constrain or bias the distribution of phenotypes produced. Moreover, when suitable heritable variation exists, natural selection may alter such constraints and correlations, affecting the phenotypic variation available to subsequent selection. However, exactly how the distribution of phenotypes produced by complex developmental systems can be shaped by past selective environments is poorly understood. Here we investigate the evolution of a network of recurrent nonlinear ontogenetic interactions, such as a gene regulation network, in various selective scenarios. We find that evolved networks of this type can exhibit several phenomena that are familiar in cognitive learning systems. These include formation of a distributed associative memory that can “store” and “recall” multiple phenotypes that have been selected in the past, recreate complete adult phenotypic patterns accurately from partial or corrupted embryonic phenotypes, and “generalize” (by exploiting evolved developmental modules) to produce new combinations of phenotypic features. We show that these surprising behaviors follow from an equivalence between the action of natural selection on phenotypic correlations and associative learning, well-understood in the context of neural networks. This helps to explain how development facilitates the evolution of high-fitness phenotypes and how this ability changes over evolutionary time.},
  year     = {2014}
}

@article{advanced-paper,
  doi       = {10.1371/journal.pcbi.1005358},
  author    = {Kouvaris, Kostas AND Clune, Jeff AND Kounios, Loizos AND Brede, Markus AND Watson, Richard A.},
  journal   = {PLOS Computational Biology},
  publisher = {Public Library of Science},
  title     = {How evolution learns to generalise: Using the principles of learning theory to understand the evolution of developmental organisation},
  year      = {2017},
  month     = {04},
  volume    = {13},
  url       = {https://doi.org/10.1371/journal.pcbi.1005358},
  pages     = {1-20},
  abstract  = {One of the most intriguing questions in evolution is how organisms exhibit suitable phenotypic variation to rapidly adapt in novel selective environments. Such variability is crucial for evolvability, but poorly understood. In particular, how can natural selection favour developmental organisations that facilitate adaptive evolution in previously unseen environments? Such a capacity suggests foresight that is incompatible with the short-sighted concept of natural selection. A potential resolution is provided by the idea that evolution may discover and exploit information not only about the particular phenotypes selected in the past, but their underlying structural regularities: new phenotypes, with the same underlying regularities, but novel particulars, may then be useful in new environments. If true, we still need to understand the conditions in which natural selection will discover such deep regularities rather than exploiting ‘quick fixes’ (i.e., fixes that provide adaptive phenotypes in the short term, but limit future evolvability). Here we argue that the ability of evolution to discover such regularities is formally analogous to learning principles, familiar in humans and machines, that enable generalisation from past experience. Conversely, natural selection that fails to enhance evolvability is directly analogous to the learning problem of over-fitting and the subsequent failure to generalise. We support the conclusion that evolving systems and learning systems are different instantiations of the same algorithmic principles by showing that existing results from the learning domain can be transferred to the evolution domain. Specifically, we show that conditions that alleviate over-fitting in learning systems successfully predict which biological conditions (e.g., environmental variation, regularity, noise or a pressure for developmental simplicity) enhance evolvability. This equivalence provides access to a well-developed theoretical framework from learning theory that enables a characterisation of the general conditions for the evolution of evolvability.},
  number    = {4}
}

@article{grn-1,
  title    = {Neural Model of the Genetic Network*},
  journal  = {Journal of Biological Chemistry},
  volume   = {276},
  number   = {39},
  pages    = {36168-36173},
  year     = {2001},
  issn     = {0021-9258},
  doi      = {https://doi.org/10.1074/jbc.M104391200},
  url      = {https://www.sciencedirect.com/science/article/pii/S002192582086685X},
  author   = {Jiri Vohradsky},
  abstract = {Many cell control processes consist of networks of interacting elements that affect the state of each other over time. Such an arrangement resembles the principles of artificial neural networks, in which the state of a particular node depends on the combination of the states of other neurons. The λ bacteriophage lysis/lysogeny decision circuit can be represented by such a network. It is used here as a model for testing the validity of a neural approach to the analysis of genetic networks. The model considers multigenic regulation including positive and negative feedback. It is used to simulate the dynamics of the lambda phage regulatory system; the results are compared with experimental observation. The comparison proves that the neural network model describes behavior of the system in full agreement with experiments; moreover, it predicts its function in experimentally inaccessible situations and explains the experimental observations. The application of the principles of neural networks to the cell control system leads to conclusions about the stability and redundancy of genetic networks and the cell functionality. Reverse engineering of the biochemical pathways from proteomics and DNA micro array data using the suggested neural network model is discussed.}
}

@article{what-is-grn,
  author   = {Michael Levine  and Eric H. Davidson },
  title    = {Gene regulatory networks for development},
  journal  = {Proceedings of the National Academy of Sciences},
  volume   = {102},
  number   = {14},
  pages    = {4936-4942},
  year     = {2005},
  doi      = {10.1073/pnas.0408031102},
  url      = {https://www.pnas.org/doi/abs/10.1073/pnas.0408031102},
  eprint   = {https://www.pnas.org/doi/pdf/10.1073/pnas.0408031102},
  abstract = {The genomic program for development operates primarily by the regulated expression of genes encoding transcription factors and components of cell signaling pathways. This program is executed by cis-regulatory DNAs (e.g., enhancers and silencers) that control gene expression. The regulatory inputs and functional outputs of developmental control genes constitute network-like architectures. In this PNAS Special Feature are assembled papers on developmental gene regulatory networks governing the formation of various tissues and organs in nematodes, flies, sea urchins, frogs, and mammals. Here, we survey salient points of these networks, by using as reference those governing specification of the endomesoderm in sea urchin embryos and dorsal–ventral patterning in the Drosophila embryo.}
}



@article{evolving-grns,
  author   = {Eric H. Davidson  and Douglas H. Erwin },
  title    = {Gene Regulatory Networks and the Evolution of Animal Body Plans},
  journal  = {Science},
  volume   = {311},
  number   = {5762},
  pages    = {796-800},
  year     = {2006},
  doi      = {10.1126/science.1113832},
  url      = {https://www.science.org/doi/abs/10.1126/science.1113832},
  eprint   = {https://www.science.org/doi/pdf/10.1126/science.1113832},
  abstract = {Development of the animal body plan is controlled by large gene regulatory networks (GRNs), and hence evolution of body plans must depend upon change in the architecture of developmental GRNs. However, these networks are composed of diverse components that evolve at different rates and in different ways. Because of the hierarchical organization of developmental GRNs, some kinds of change affect terminal properties of the body plan such as occur in speciation, whereas others affect major aspects of body plan morphology. A notable feature of the paleontological record of animal evolution is the establishment by the Early “Cambrian of virtually all phylum-level body plans. We identify a class of GRN component, the kernels” of the network, which, because of their developmental role and their particular internal structure, are most impervious to change. Conservation of phyletic body plans may have been due to the retention since pre-Cambrian time of GRN kernels, which underlie development of major body parts.}
}

@article{evo-speed-grn,
  title    = {Genetic variation in pleiotropy: differential epistasis as a
              source of variation in the allometric relationship between long
              bone lengths and body weight},
  author   = {Pavlicev, Mihaela and Kenney-Hunt, Jane P and Norgard, Elizabeth
              A and Roseman, Charles C and Wolf, Jason B and Cheverud, James M},
  abstract = {Pleiotropy is an aspect of genetic architecture underlying the
              phenotypic covariance structure. The presence of genetic
              variation in pleiotropy is necessary for natural selection to
              shape patterns of covariation between traits. We examined the
              contribution of differential epistasis to variation in the
              intertrait relationship and the nature of this variation. Genetic
              variation in pleiotropy was revealed by mapping quantitative
              trait loci (QTLs) affecting the allometry of mouse limb and tail
              length relative to body weight in the mouse-inbred strain LG/J by
              SM/J intercross. These relationship QTLs (rQTLs) modify
              relationships between the traits affected by a common pleiotropic
              locus. We detected 11 rQTLs, mostly affecting allometry of
              multiple bones. We further identified epistatic interactions
              responsible for the observed allometric variation. Forty loci
              that interact epistatically with the detected rQTLs were
              identified. We demonstrate how these epistatic interactions
              differentially affect the body size variance and the covariance
              of traits with body size. We conclude that epistasis, by
              differentially affecting both the canalization and mean values of
              the traits of a pleiotropic domain, causes variation in the
              covariance structure. Variation in pleiotropy maintains
              evolvability of the genetic architecture, in particular the
              evolvability of its modular organization.},
  journal  = {Evolution},
  volume   = 62,
  number   = 1,
  pages    = {199--213},
  month    = nov,
  year     = 2007,
  address  = {United States},
  language = {en}
}

@article{grn-learn-from-past,
  doi       = {10.1371/journal.pcbi.1000206},
  author    = {Parter, Merav AND Kashtan, Nadav AND Alon, Uri},
  journal   = {PLOS Computational Biology},
  publisher = {Public Library of Science},
  title     = {Facilitated Variation: How Evolution Learns from Past Environments To Generalize to New Environments},
  year      = {2008},
  month     = {11},
  volume    = {4},
  url       = {https://doi.org/10.1371/journal.pcbi.1000206},
  pages     = {1-15},
  abstract  = {One of the striking features of evolution is the appearance of novel structures in organisms. Recently, Kirschner and Gerhart have integrated discoveries in evolution, genetics, and developmental biology to form a theory of facilitated variation (FV). The key observation is that organisms are designed such that random genetic changes are channeled in phenotypic directions that are potentially useful. An open question is how FV spontaneously emerges during evolution. Here, we address this by means of computer simulations of two well-studied model systems, logic circuits and RNA secondary structure. We find that evolution of FV is enhanced in environments that change from time to time in a systematic way: the varying environments are made of the same set of subgoals but in different combinations. We find that organisms that evolve under such varying goals not only remember their history but also generalize to future environments, exhibiting high adaptability to novel goals. Rapid adaptation is seen to goals composed of the same subgoals in novel combinations, and to goals where one of the subgoals was never seen in the history of the organism. The mechanisms for such enhanced generation of novelty (generalization) are analyzed, as is the way that organisms store information in their genomes about their past environments. Elements of facilitated variation theory, such as weak regulatory linkage, modularity, and reduced pleiotropy of mutations, evolve spontaneously under these conditions. Thus, environments that change in a systematic, modular fashion seem to promote facilitated variation and allow evolution to generalize to novel conditions.},
  number    = {11}
}